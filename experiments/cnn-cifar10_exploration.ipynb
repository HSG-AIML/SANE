{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feccff84-d70f-42c8-be6d-406878c20653",
   "metadata": {},
   "source": [
    "# SANE Exploration\n",
    "\n",
    "In this notebook, we explore SANE datasets, models, training and inference as an easy starting point.\n",
    "This notebook uses a sample dataset. To prepare that, navigate to SANE/data, and run `bash download_cifar10_cnn_sample.sh` to download the sample dataset, and `python3 preprocess_dataset_cnn_cifar10_sample.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cf67f8-9fcf-4cd9-bd71-1427421f600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp1cr6k324\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp1cr6k324/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from SANE.evaluation.ray_fine_tuning_callback import CheckpointSamplingCallback\n",
    "from SANE.evaluation.ray_fine_tuning_callback_subsampled import (\n",
    "    CheckpointSamplingCallbackSubsampled,\n",
    ")\n",
    "from SANE.evaluation.ray_fine_tuning_callback_bootstrapped import (\n",
    "    CheckpointSamplingCallbackBootstrapped,\n",
    ")\n",
    "\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from SANE.models.ae_trainer import AE_trainer\n",
    "from SANE.datasets.dataset_sampling_preprocessed import PreprocessedSamplingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae6c617-ed3c-4559-991b-68daed70d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ROOT = Path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3b83e0f-1a77-416b-893e-0061fac876ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:prepare data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'seed': 32,\n",
       " 'device': 'cpu',\n",
       " 'device_no': 1,\n",
       " 'ae:transformer_type': 'gpt2',\n",
       " 'ae:i_dim': 289,\n",
       " 'ae:lat_dim': 128,\n",
       " 'ae:max_positions': [100, 10, 40],\n",
       " 'ae:d_model': 1024,\n",
       " 'ae:nhead': 8,\n",
       " 'ae:num_layers': 8,\n",
       " 'training::permutation_number': 5,\n",
       " 'training::view_2_canon': True,\n",
       " 'testing::permutation_number': 5,\n",
       " 'testing::view_1_canon': True,\n",
       " 'testing::view_2_canon': False,\n",
       " 'trainset::add_noise_view_1': 0.1,\n",
       " 'trainset::add_noise_view_2': 0.1,\n",
       " 'trainset::noise_multiplicative': True,\n",
       " 'trainset::erase_augment_view_1': None,\n",
       " 'trainset::erase_augment_view_2': None,\n",
       " 'training::windowsize': 64,\n",
       " 'trainset::batchsize': 32,\n",
       " 'optim::optimizer': 'adamw',\n",
       " 'optim::lr': 0.0001,\n",
       " 'optim::wd': 3e-09,\n",
       " 'optim::scheduler': 'OneCycleLR',\n",
       " 'training::temperature': 0.1,\n",
       " 'training::gamma': 0.05,\n",
       " 'training::reduction': 'mean',\n",
       " 'training::contrast': 'simclr',\n",
       " 'training::epochs_train': 50,\n",
       " 'training::output_epoch': 25,\n",
       " 'training::test_epochs': 1,\n",
       " 'model::compile': True,\n",
       " 'training::precision': 'amp',\n",
       " 'monitor_memory': True,\n",
       " 'trainloader::workers': 6,\n",
       " 'experiment_dir': PosixPath('sane_pretraining'),\n",
       " 'dataset::dump': PosixPath('../data/dataset_cnn_cifar10_sample_ep21-25_std/dataset.pt'),\n",
       " 'downstreamtask::dataset': None,\n",
       " 'callbacks': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure SANE pretraining\n",
    "\n",
    "### configure experiment #########\n",
    "experiment_name = \"sane_cifar10_cnn_standalone\"\n",
    "# set module parameters\n",
    "config = {}\n",
    "config[\"seed\"] = 32\n",
    "config[\"device\"] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config[\"device_no\"] = 1\n",
    "\n",
    "config[\"ae:transformer_type\"] = \"gpt2\"\n",
    "config[\"ae:i_dim\"] = 288\n",
    "config[\"ae:i_dim\"] = 289\n",
    "config[\"ae:lat_dim\"] = 128\n",
    "config[\"ae:max_positions\"] = [100, 10, 40]\n",
    "config[\"ae:d_model\"] = 1024\n",
    "config[\"ae:nhead\"] = 8\n",
    "config[\"ae:num_layers\"] = 8\n",
    "\n",
    "# permutation specs\n",
    "config[\"training::permutation_number\"] = 5\n",
    "config[\"training::view_2_canon\"] = False\n",
    "config[\"training::view_2_canon\"] = True\n",
    "config[\"testing::permutation_number\"] = 5\n",
    "config[\"testing::view_1_canon\"] = True\n",
    "config[\"testing::view_2_canon\"] = False\n",
    "### Augmentations\n",
    "config[\"trainset::add_noise_view_1\"] = 0.1\n",
    "config[\"trainset::add_noise_view_2\"] = 0.1\n",
    "config[\"trainset::noise_multiplicative\"] = True\n",
    "config[\"trainset::erase_augment_view_1\"] = None\n",
    "config[\"trainset::erase_augment_view_2\"] = None\n",
    "\n",
    "config[\"training::windowsize\"] = 64\n",
    "config[\"trainset::batchsize\"] = 32\n",
    "\n",
    "# configure optimizer\n",
    "config[\"optim::optimizer\"] = \"adamw\"\n",
    "config[\"optim::lr\"] = 1e-4\n",
    "config[\"optim::wd\"] = 3e-9\n",
    "config[\"optim::scheduler\"] = \"OneCycleLR\"\n",
    "\n",
    "# Task config\n",
    "config[\"training::temperature\"] = 0.1\n",
    "config[\"training::gamma\"] = 0.05\n",
    "config[\"training::reduction\"] = \"mean\"\n",
    "config[\"training::contrast\"] = \"simclr\"\n",
    "\n",
    "# training duration\n",
    "config[\"training::epochs_train\"] = 5\n",
    "config[\"training::output_epoch\"] = 5\n",
    "config[\"training::test_epochs\"] = 1\n",
    "\n",
    "# training optimization\n",
    "config[\"model::compile\"] = True\n",
    "config[\"training::precision\"] = \"amp\"\n",
    "config[\"training::reduction\"] = \"mean\"\n",
    "config[\"monitor_memory\"] = True\n",
    "config[\"trainloader::workers\"] = 6\n",
    "\n",
    "# configure output path\n",
    "experiment_dir = PATH_ROOT.joinpath(\"sane_pretraining\")\n",
    "try:\n",
    "    experiment_dir.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "config['experiment_dir'] = experiment_dir\n",
    "###### Datasets ###########################################################################\n",
    "# pre-compute dataset and drop in torch.save\n",
    "data_path = Path(\"../data/dataset_cnn_cifar10_sample_ep21-25_std/\")\n",
    "# path to dataset for training\n",
    "config[\"dataset::dump\"] = data_path.joinpath(\"dataset.pt\")\n",
    "config[\"downstreamtask::dataset\"] = None\n",
    "# call dataset prepper function\n",
    "logging.info(\"prepare data\")\n",
    "\n",
    "\n",
    "config[\"callbacks\"] = []\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a266467d-3e1d-4fe2-9333-bfced1ec871a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Set up AE Trainable\n",
      "INFO:root:get datasets\n",
      "INFO:root:Load Data\n",
      "INFO:root:set up dataloaders\n",
      "INFO:root:corrected batchsize to 32\n",
      "INFO:root:set downstream tasks\n",
      "INFO:root:No properties found in dataset - skip downstream tasks.\n",
      "INFO:root:instanciate model\n",
      "INFO:root:Initialize Model\n",
      "INFO: Global seed set to 32\n",
      "INFO:lightning.fabric.utilities.seed:Global seed set to 32\n",
      "INFO:root:device: cpu\n",
      "INFO:root:compiling the model... (takes a ~minute)\n",
      "INFO:root:compiled successfully\n",
      "INFO:root:set transformations\n",
      "INFO:root:set callbacks\n",
      "INFO:root:module setup done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: use simclr NT_Xent loss\n",
      "Running single-gpu. send model to device: cpu\n",
      "num decayed parameter tensors: 73, with 202,504,068 parameters\n",
      "num non-decayed parameter tensors: 40, with 35,353 parameters\n",
      "using fused AdamW: False\n",
      "++++++ USE AUTOMATIC MIXED PRECISION +++++++\n"
     ]
    }
   ],
   "source": [
    "# init ae_trainer - this sets up the model, loads the dataset and configures the training loop.\n",
    "ae_trainer = AE_trainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab3def-32eb-4aee-986c-77357808fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training loop\n",
    "ae_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b5b7d6d-4010-449b-ad8a-20073c98c02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: torch.Size([32, 201, 64, 289]) - mask: torch.Size([32, 64, 289]) - positions: torch.Size([32, 64, 3]) - properties: torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "# get data for further exploration\n",
    "batch = next(iter(ae_trainer.trainloader))\n",
    "tokens, mask, positions, properties = batch\n",
    "print(f'tokens: {tokens.shape} - mask: {mask.shape} - positions: {positions.shape} - properties: {properties.shape}')\n",
    "# tokens are of shape [batch_size, no_permutations, sequence_length, token_size]\n",
    "# masks are of shape [batch_size, sequence_length, token_size]\n",
    "# positions are of shape [batch_size, sequence_length, 3]\n",
    "# properties are of shape [batch_size, 3]\n",
    "\n",
    "tokens = tokens[:,0,:,:].squeeze() # choose one permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1663c8fa-5917-43d4-bb15-1ce1b2d4a939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: torch.Size([32, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "# compute embeddings\n",
    "with torch.no_grad():\n",
    "    z = ae_trainer.module.forward_encoder(tokens,positions.to(torch.int))\n",
    "print(f'z: {z.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "397ac6fc-0001-4360-b803-c9d904805e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_recon: torch.Size([32, 64, 289])\n"
     ]
    }
   ],
   "source": [
    "# decode to weights\n",
    "with torch.no_grad():\n",
    "    tokens_recon = ae_trainer.module.forward_decoder(z,positions.to(torch.int))\n",
    "print(f'tokens_recon: {tokens_recon.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6490ca2-6763-4d02-b24c-9d6cf96a465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CNN model\n",
    "\n",
    "from SANE.models.def_net import NNmodule\n",
    "\n",
    "\n",
    "config_cnn_path = Path('../data/cifar10_cnn_sample_ep21-25/NN_tune_trainable_da045_00000_0_seed=1_2021-09-25_11-43-53/params.json')\n",
    "config_cnn = json.load(config_cnn_path.open('r'))\n",
    "\n",
    "cnn = NNmodule(config_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04e4755a-7704-4c9d-b2ea-ae4a11278c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['module_list.0.weight', 'module_list.0.bias', 'module_list.4.weight', 'module_list.4.bias', 'module_list.8.weight', 'module_list.8.bias', 'module_list.13.weight', 'module_list.13.bias', 'module_list.16.weight', 'module_list.16.bias'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get cnn checkpoint\n",
    "\n",
    "check = cnn.model.state_dict()\n",
    "check.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7456722b-cc87-4935-a1b4-eaafaf5a3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize checkpoint \n",
    "from SANE.datasets.dataset_auxiliaries import tokenize_checkpoint\n",
    "toks, masks, pos = tokenize_checkpoint(check,tokensize=0,return_mask=True)\n",
    "toks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7739962e-b5a6-4633-b6b9-450674f39c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize checkpoint \n",
    "from SANE.datasets.dataset_auxiliaries import tokens_to_checkpoint\n",
    "check_recon = tokens_to_checkpoint(tokens=toks, pos=pos, reference_checkpoint=check, ignore_bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "223abe3b-8cd2-40c7-ab34-5e7624d73659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assert equivalence\n",
    "torch.allclose(check['module_list.0.weight'],check_recon['module_list.0.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0678791-4247-491a-8fdf-4207aa2bcc6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
